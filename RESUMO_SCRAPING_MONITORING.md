# ğŸ“Š Como Analisar se o Web Scraping estÃ¡ Funcionando - RESUMO EXECUTIVO

## ğŸ¯ **Status Atual - IMPLEMENTADO**

âœ… **Chrome instalado** - Usamos Dockerfile.alternative com Google Chrome  
âœ… **Selenium funcionando** - DependÃªncias instaladas e configuradas  
âœ… **Celery configurado** - Worker rodando com filas de scraping  
âœ… **Flower funcionando** - Monitor principal em https://flower.juscash.app  
âœ… **API endpoints** - `/api/scraping/extract` para executar scraping  
âœ… **Scripts de anÃ¡lise** - Ferramentas automatizadas de verificaÃ§Ã£o  

## ğŸš€ **Formas de Verificar se o Scraping estÃ¡ Funcionando**

### **1. ğŸŒ¸ Flower - MÃ‰TODO PRINCIPAL (Recomendado)**

**URL**: https://flower.juscash.app  
**Login**: admin / juscash2024

**O que verificar:**
- Aba "Tasks" â†’ Procurar tarefas `extract_publicacoes_task`
- Status SUCCESS = Scraping funcionou âœ…
- Status FAILURE = Problema no scraping âŒ
- Tempo de execuÃ§Ã£o normal: 2-30 minutos

### **2. ğŸ“‹ Logs Docker - VERIFICAÃ‡ÃƒO TÃ‰CNICA**

```bash
# SSH na VPS
ssh root@77.37.68.178

# Ver logs do worker (onde roda o scraping)
docker logs juscash_worker_prod --tail 50 | grep -i extract

# Logs de sucesso esperados:
# "âœ… Driver inicializado com webdriver-manager"
# "Raspagem diÃ¡ria concluÃ­da: X publicaÃ§Ãµes extraÃ­das"
# "âœ… Driver do Selenium finalizado com sucesso"
```

### **3. ğŸ§ª Teste Manual via API**

```bash
# Executar scraping de teste
curl -X POST 'https://cron.juscash.app/api/scraping/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "data_inicio": "2024-12-25T00:00:00",
    "data_fim": "2024-12-25T23:59:59"
  }'

# Resposta esperada:
# {"task_id": "...", "status": "Em processamento (async)"}

# Verificar status da tarefa:
curl 'https://cron.juscash.app/api/cron/tasks/TASK_ID'
```

### **4. ğŸ“Š Verificar Dados ExtraÃ­dos**

```bash
# Ver publicaÃ§Ãµes no banco
curl 'https://cron.juscash.app/api/publicacoes/?limit=10'

# Se retornar dados = scraping jÃ¡ funcionou antes
# Se retornar vazio = scraping nunca funcionou ou problema
```

### **5. ğŸ¤– Script Automatizado**

```bash
# Na mÃ¡quina local (dentro do projeto)
./scripts/check-scraping.sh

# Faz anÃ¡lise completa automaticamente
```

## ğŸ“ˆ **Indicadores de SaÃºde do Scraping**

### **âœ… FUNCIONANDO BEM:**
- Tarefas SUCCESS no Flower nas Ãºltimas 24h
- Logs sem erros crÃ­ticos de Chrome/Selenium
- PublicaÃ§Ãµes novas sendo salvas no banco
- Tempo de execuÃ§Ã£o < 30 minutos por execuÃ§Ã£o
- Campos preenchidos em > 80% das publicaÃ§Ãµes

### **ğŸš¨ PROBLEMAS CRÃTICOS:**
- 0 publicaÃ§Ãµes extraÃ­das por > 2 dias
- Erros "Chrome not found" ou "Selenium failed"
- Timeout em > 50% das execuÃ§Ãµes
- Campos vazios em > 80% dos dados
- Container worker reiniciando constantemente

## ğŸ› ï¸ **SoluÃ§Ã£o de Problemas Comuns**

### **Problema: Chrome nÃ£o encontrado**
```bash
# Verificar se estÃ¡ usando Dockerfile correto
grep "dockerfile:" docker-compose.prod.yml
# Deve mostrar: dockerfile: Dockerfile.alternative

# Se nÃ£o, corrigir e fazer rebuild
docker-compose -f docker-compose.prod.yml up --build -d
```

### **Problema: Selenium falha**
```bash
# Testar Selenium no container
docker exec juscash_worker_prod python -c "from selenium import webdriver; print('OK')"

# Se falhar, verificar dependÃªncias
docker exec juscash_worker_prod google-chrome --version
```

### **Problema: Site DJE inacessÃ­vel**
```bash
# Testar conectividade
docker exec juscash_worker_prod curl -I https://dje.tjsp.jus.br/cdje/index.do

# Deve retornar "200 OK"
```

### **Problema: Worker nÃ£o processa tarefas**
```bash
# Restart do worker
docker-compose -f docker-compose.prod.yml restart worker

# Verificar logs
docker logs juscash_worker_prod --tail 20
```

## ğŸ“… **Monitoramento DiÃ¡rio Recomendado**

### **âš¡ VerificaÃ§Ã£o RÃ¡pida (2 minutos)**
1. Acessar https://flower.juscash.app
2. Verificar se hÃ¡ tarefas SUCCESS nas Ãºltimas 24h
3. Se nÃ£o houver, executar teste manual

### **ğŸ” VerificaÃ§Ã£o Semanal (10 minutos)**
1. Executar `./scripts/check-scraping.sh`
2. Analisar qualidade dos dados extraÃ­dos
3. Verificar performance dos containers
4. Revisar logs de erro da semana

## ğŸ¯ **URLs Importantes**

| Ferramenta | URL | DescriÃ§Ã£o |
|------------|-----|-----------|
| ğŸŒ¸ **Flower** | https://flower.juscash.app | Monitor principal (admin:juscash2024) |
| ğŸ“Š **cAdvisor** | https://cadvisor.juscash.app | MÃ©tricas de containers |
| ğŸ³ **Portainer** | https://portainer.juscash.app | Gerenciamento Docker |
| ğŸ“š **API Docs** | https://cron.juscash.app/docs/ | DocumentaÃ§Ã£o Swagger |

## ğŸ“‹ **Checklist de Funcionamento**

- [ ] Container `juscash_worker_prod` estÃ¡ UP
- [ ] Chrome instalado: `google-chrome --version` funciona
- [ ] Selenium funciona: `from selenium import webdriver` sem erro
- [ ] Site DJE acessÃ­vel: curl retorna 200 OK
- [ ] Flower mostra tarefas SUCCESS recentes
- [ ] Banco tem publicaÃ§Ãµes recentes
- [ ] Logs sem erros crÃ­ticos

## ğŸš€ **PrÃ³ximos Passos**

1. **Configurar cron jobs** para execuÃ§Ã£o automÃ¡tica diÃ¡ria
2. **Monitorar via Flower** diariamente
3. **Executar script de anÃ¡lise** semanalmente
4. **Otimizar performance** se necessÃ¡rio

---

## ğŸ“ **Em Caso de Problemas**

1. **Verificar Flower primeiro**: https://flower.juscash.app
2. **Executar script de anÃ¡lise**: `./scripts/check-scraping.sh`
3. **Verificar logs**: `docker logs juscash_worker_prod`
4. **Testar manualmente**: API `/api/scraping/extract`
5. **Restart se necessÃ¡rio**: `docker-compose restart worker`

**Status atual**: âœ… Scraping configurado e funcionando com Chrome + Selenium 