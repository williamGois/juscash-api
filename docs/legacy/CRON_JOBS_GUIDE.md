# üïê Guia de Cron Jobs - JusCash API

Este documento explica como configurar e gerenciar os cron jobs para automa√ß√£o da raspagem de dados do DJE.

## üöÄ Op√ß√µes de Agendamento

A JusCash API oferece **duas formas** de configurar tarefas autom√°ticas:

### 1. **Celery Beat** (Recomendado para Docker)
- ‚úÖ Integrado com o Docker Compose
- ‚úÖ Interface web com Flower
- ‚úÖ Gerenciamento via API
- ‚úÖ Logs centralizados

### 2. **Crontab do Sistema** (Para servidores Linux)
- ‚úÖ Nativo do sistema operacional
- ‚úÖ Independente do Docker
- ‚úÖ Controle granular de hor√°rios

## üê≥ Configura√ß√£o com Docker (Celery Beat)

### Estrutura dos Containers

```yaml
# docker-compose.yml inclui:
- web              # API Flask
- celery-worker    # Processador de tarefas
- celery-beat      # Agendador de tarefas
- celery-flower    # Interface de monitoramento
- redis            # Message broker
- db               # PostgreSQL
```

### Agendamentos Configurados

| Tarefa | Frequ√™ncia | Hor√°rio | Descri√ß√£o |
|--------|-----------|---------|-----------|
| **Raspagem Di√°ria** | A cada hora | Configur√°vel | Extrai publica√ß√µes do dia anterior |
| **Raspagem Completa** | Semanal | Configur√°vel | Extrai todo o per√≠odo (01/10 - 29/11/2024) |
| **Limpeza de Logs** | Di√°ria | Configur√°vel | Remove logs antigos (>30 dias) |

### Vari√°veis de Ambiente

```env
# Agendamentos (em segundos)
DAILY_SCRAPING_SCHEDULE=3600    # 1 hora
WEEKLY_SCRAPING_SCHEDULE=604800 # 1 semana  
CLEANUP_SCHEDULE=86400          # 1 dia

# Controle
SCRAPING_ENABLED=true           # Habilitar/desabilitar
```

### Comandos Docker

```bash
# Executar todos os servi√ßos
docker-compose up --build

# Ver logs espec√≠ficos
docker-compose logs -f celery-beat
docker-compose logs -f celery-worker

# Monitoramento web (Flower)
# Acesse: http://localhost:5555

# Executar tarefa manual
docker-compose exec web python -c "
from app.tasks.scraping_tasks import extract_daily_publicacoes
extract_daily_publicacoes.delay()
"
```

## üñ•Ô∏è Configura√ß√£o com Crontab (Sistema Linux)

### Instala√ß√£o Autom√°tica

```bash
# Instalar cron jobs
python cron_schedule.py install

# Verificar status
python cron_schedule.py status

# Remover cron jobs
python cron_schedule.py remove
```

### Agendamentos Padr√£o

```cron
# Raspagem di√°ria √†s 2:00 AM
0 2 * * * cd /path/to/juscash-api && python -c "..."

# Raspagem completa aos domingos √†s 3:00 AM  
0 3 * * 0 cd /path/to/juscash-api && python -c "..."

# Limpeza de logs √†s 4:00 AM
0 4 * * * cd /path/to/juscash-api && python -c "..."

# Health check a cada 6 horas
0 */6 * * * cd /path/to/juscash-api && python -c "..."
```

### Configura√ß√£o Manual

```bash
# Editar crontab
crontab -e

# Adicionar entrada personalizada
# Min Hora Dia M√™s DiaSemana Comando
0 8 * * 1-5 cd /path/to/juscash-api && python -c "from app.tasks.scraping_tasks import extract_daily_publicacoes; extract_daily_publicacoes.delay()"

# Ver crontab atual
crontab -l
```

## üìä API de Gerenciamento de Cron Jobs

A API inclui endpoints para gerenciar tarefas manualmente:

### Endpoints Dispon√≠veis

```http
# Execu√ß√£o Manual
POST /api/cron/scraping/daily
POST /api/cron/scraping/full-period
POST /api/cron/scraping/custom-period
POST /api/cron/maintenance/cleanup
POST /api/cron/maintenance/stats

# Monitoramento
GET /api/cron/health
GET /api/cron/tasks/{task_id}
```

### Exemplos de Uso

```bash
# Executar raspagem di√°ria
curl -X POST http://localhost:5000/api/cron/scraping/daily

# Executar raspagem customizada
curl -X POST http://localhost:5000/api/cron/scraping/custom-period \
  -H "Content-Type: application/json" \
  -d '{"data_inicio": "2024-10-01", "data_fim": "2024-10-31"}'

# Verificar sa√∫de do sistema
curl http://localhost:5000/api/cron/health

# Verificar status de tarefa
curl http://localhost:5000/api/cron/tasks/task-id-aqui
```

## üîç Monitoramento e Logs

### Flower (Interface Web)

```bash
# Acessar Flower
http://localhost:5555

# Funcionalidades:
- ‚úÖ Tasks em execu√ß√£o
- ‚úÖ Hist√≥rico de execu√ß√µes  
- ‚úÖ Estat√≠sticas de performance
- ‚úÖ Controle de workers
```

### Logs do Sistema

```bash
# Docker logs
docker-compose logs -f celery-beat
docker-compose logs -f celery-worker

# Logs do sistema (crontab)
tail -f /var/log/juscash-daily.log
tail -f /var/log/juscash-weekly.log
tail -f /var/log/juscash-cleanup.log
tail -f /var/log/juscash-health.log
```

### Health Check

```bash
# Via API
curl http://localhost:5000/api/cron/health

# Via comando direto
docker-compose exec web python -c "
from app.tasks.maintenance_tasks import health_check
print(health_check.delay().get())
"
```

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Personalizar Hor√°rios

```python
# config.py
DAILY_SCRAPING_SCHEDULE = 1800  # 30 minutos
WEEKLY_SCRAPING_SCHEDULE = 259200  # 3 dias
CLEANUP_SCHEDULE = 43200  # 12 horas
```

### Desabilitar Raspagem

```env
SCRAPING_ENABLED=false
```

### Configurar Retry e Timeout

```python
# app/tasks/scraping_tasks.py
@celery.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3, 'countdown': 60})
def extract_daily_publicacoes(self):
    # ... c√≥digo da tarefa
```

## üö® Troubleshooting

### Problemas Comuns

**1. Tarefa n√£o executa**
```bash
# Verificar se worker est√° rodando
docker-compose ps
celery -A celery_worker.celery inspect active

# Verificar logs
docker-compose logs celery-beat
```

**2. Erro de conex√£o com banco**
```bash
# Verificar vari√°veis de ambiente
docker-compose exec web env | grep DATABASE

# Testar conex√£o
docker-compose exec web python -c "
from app import create_app, db
app = create_app()
with app.app_context():
    print(db.engine.execute('SELECT 1').scalar())
"
```

**3. Crontab n√£o funciona**
```bash
# Verificar se cron est√° rodando
sudo systemctl status cron

# Ver logs do cron
tail -f /var/log/syslog | grep CRON

# Testar comando manualmente
cd /path/to/juscash-api && python -c "..."
```

**4. Flower n√£o carrega**
```bash
# Verificar se Redis est√° rodando
docker-compose exec redis redis-cli ping

# Reiniciar flower
docker-compose restart celery-flower
```

### Comandos de Diagn√≥stico

```bash
# Status completo do sistema
curl http://localhost:5000/api/cron/health

# Tasks ativas
docker-compose exec web celery -A celery_worker.celery inspect active

# Estat√≠sticas
docker-compose exec web celery -A celery_worker.celery inspect stats

# Configura√ß√£o atual
docker-compose exec web python -c "
from app import create_app
app = create_app()
print(app.config['DAILY_SCRAPING_SCHEDULE'])
"
```

## üìã Checklist de Produ√ß√£o

### Antes do Deploy

- [ ] Configurar vari√°veis de ambiente
- [ ] Definir hor√°rios apropriados
- [ ] Configurar alertas de falha
- [ ] Testar todas as tarefas manualmente
- [ ] Configurar monitoramento (Flower)
- [ ] Configurar backup do Redis
- [ ] Documentar procedimentos

### Monitoramento Cont√≠nuo

- [ ] Verificar logs diariamente
- [ ] Monitorar performance via Flower
- [ ] Acompanhar health checks
- [ ] Validar dados extra√≠dos
- [ ] Verificar espa√ßo em disco
- [ ] Monitorar uso de CPU/RAM

## üéØ Resumo dos Comandos

```bash
# Docker (Recomendado)
docker-compose up --build                    # Iniciar todos os servi√ßos
docker-compose logs -f celery-beat          # Logs do agendador
http://localhost:5555                       # Interface Flower

# Crontab (Alternativo)
python cron_schedule.py install            # Instalar cron jobs
python cron_schedule.py status             # Ver status
crontab -l                                 # Listar entradas

# API Manual
curl -X POST http://localhost:5000/api/cron/scraping/daily
curl http://localhost:5000/api/cron/health
```

Agora voc√™ tem um sistema completo de automa√ß√£o para manter sua base de dados sempre atualizada! üöÄ 